#!/usr/bin/env python3
"""
Generate spec-driven tests from official CPython resources.

Regenerate with:
  python3 scripts/generate_spec_tests.py
"""

from __future__ import annotations

import ast
import contextlib
import html
import importlib
import io
import json
import math
import re
import signal
import textwrap
import tokenize
import urllib.request
import warnings
from pathlib import Path
from typing import Any, List, Optional, Tuple

OUTPUT_FILE = Path(__file__).parent.parent / "spec_generated_test.mbt"
CPYTHON_ROOT = Path(__file__).parent.parent / "cpython-tests"
CPYTHON_TEST_DIR = CPYTHON_ROOT / "Lib" / "test"
REFERENCE_VERSION = "3.13"
REFERENCE_CACHE = Path(__file__).parent / "reference_cache" / REFERENCE_VERSION

TOTAL_TARGET = 3000
EXPR_TARGET = 2000
PROGRAM_TARGET = 1000
MAX_TEST_FILES = 500
REFERENCE_URLS = [
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/expressions.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/simple_stmts.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/compound_stmts.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/datamodel.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/lexical_analysis.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/executionmodel.html",
]

LICENSE_HEADER = """// ============================================================================
// AUTO-GENERATED FILE - DO NOT MODIFY MANUALLY
// Generated by: scripts/generate_spec_tests.py
// Regenerate with: python3 scripts/generate_spec_tests.py
// ============================================================================

///|
/// MPython spec-driven tests generated from CPython evaluation

fn assert_run(result : Result[RunResult, RuntimeError], expected : String) -> Unit raise {
  let json = @json.parse(expected) catch { _ => fail("invalid json") }
  match json {
    Array(items) => {
      if items.length() < 2 {
        fail("invalid expectation")
      }
      let tag = items[0]
      match tag {
        String(tag) =>
          if tag == "ok" {
            if items.length() != 4 {
              fail("invalid expectation")
            }
            let payload = items[1]
            let stdout = items[2]
            let stderr = items[3]
            match result {
              Ok(run) => {
                @json.inspect(run.value, content=payload)
                match stdout {
                  String(text) => inspect(run.stdout, content=text)
                  _ => fail("invalid expectation")
                }
                match stderr {
                  String(text) => inspect(run.stderr, content=text)
                  _ => fail("invalid expectation")
                }
              }
              Err(err) => fail(format_runtime_error(err))
            }
          } else if tag == "err" {
            if items.length() != 2 {
              fail("invalid expectation")
            }
            let payload = items[1]
            match result {
              Ok(_) => fail("expected error")
              Err(err) =>
                match payload {
                  String(message) =>
                    inspect(format_runtime_error(err), content=message)
                  _ => fail("invalid error payload")
                }
            }
          } else {
            fail("invalid expectation")
          }
        _ => fail("invalid expectation")
      }
    }
    _ => fail("invalid expectation")
  }
}

"""


def escape_moonbit_string(value: str) -> str:
    value = value.replace("\\", "\\\\")
    value = value.replace('"', "\\\"")
    value = value.replace("\r", "")
    value = value.replace("\n", "\\n")
    value = value.replace("\t", "\\t")
    return value


def render_multiline_literal(name: str, text: str, indent: str = "  ") -> str:
    lines = text.splitlines()
    if text.endswith("\n"):
        lines.append("")
    result = [f"{indent}let {name} ="]
    if not lines:
        result.append(f"{indent}  #|")
        return "\n".join(result)
    for line in lines:
        result.append(f"{indent}  #|{line}")
    return "\n".join(result)


def safe_import(name: str, globals: Any = None, locals: Any = None, fromlist: Any = (), level: int = 0) -> Any:
    if name in {"math", "functools", "itertools"}:
        return importlib.import_module(name)
    raise ImportError(f"module {name} is not allowed")


SAFE_BUILTINS = {
    "__import__": safe_import,
    "len": len,
    "range": range,
    "str": str,
    "int": int,
    "float": float,
    "list": list,
    "dict": dict,
    "set": set,
    "tuple": tuple,
    "enumerate": enumerate,
    "zip": zip,
    "map": map,
    "filter": filter,
    "any": any,
    "all": all,
    "sum": sum,
    "print": print,
}


class EvalTimeout(Exception):
    pass


EVAL_TIMEOUT_SEC = 0.25


@contextlib.contextmanager
def time_limit(seconds: float) -> Any:
    def handler(signum: int, frame: Any) -> None:
        raise EvalTimeout()

    old = signal.signal(signal.SIGALRM, handler)
    try:
        signal.setitimer(signal.ITIMER_REAL, seconds)
        yield
    finally:
        signal.setitimer(signal.ITIMER_REAL, 0)
        signal.signal(signal.SIGALRM, old)


def eval_expression(expr: str) -> Tuple[Any, str, str]:
    env = {"__builtins__": SAFE_BUILTINS.copy()}
    stdout = io.StringIO()
    stderr = io.StringIO()
    with time_limit(EVAL_TIMEOUT_SEC):
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", SyntaxWarning)
            with contextlib.redirect_stdout(stdout), contextlib.redirect_stderr(stderr):
                value = eval(expr, env, env)
    return value, stdout.getvalue(), stderr.getvalue()


def eval_program(lines: List[str]) -> Tuple[Any, str, str]:
    env = {"__builtins__": SAFE_BUILTINS.copy()}
    if not lines:
        return None, "", ""
    stdout = io.StringIO()
    stderr = io.StringIO()
    with time_limit(EVAL_TIMEOUT_SEC):
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", SyntaxWarning)
            with contextlib.redirect_stdout(stdout), contextlib.redirect_stderr(stderr):
                exec("\n".join(lines), env, env)
    return None, stdout.getvalue(), stderr.getvalue()


def format_error(err: Exception) -> str:
    if isinstance(err, SyntaxError):
        line = err.lineno or 1
        column = err.offset or 1
        message = err.msg or "invalid syntax"
        return f"line {line}:{column} {message}"
    return f"{err.__class__.__name__}: {err}"



def is_supported_expr(expr: str) -> bool:
    return True


def is_supported_program(lines: List[str]) -> bool:
    return True


def value_to_json(value: Any) -> Any:
    if value is None:
        return "None"
    if isinstance(value, bool):
        return ["Bool", value]
    if isinstance(value, int):
        return ["Int", str(value)]
    if isinstance(value, float):
        if math.isnan(value) or math.isinf(value):
            raise ValueError("unsupported float")
        return ["Float", value]
    if isinstance(value, str):
        return ["Str", value]
    if isinstance(value, list):
        return ["List", [value_to_json(item) for item in value]]
    if isinstance(value, tuple):
        return ["Tuple", [value_to_json(item) for item in value]]
    if isinstance(value, set):
        return ["Set", [value_to_json(item) for item in value]]
    if isinstance(value, dict):
        return [
            "Dict",
            [[value_to_json(key), value_to_json(val)] for key, val in value.items()],
        ]
    raise ValueError("unsupported value")


def json_literal(value: Any) -> str:
    return json.dumps(value, ensure_ascii=False)


def render_expr_test(case_id: int, expr: str, expected_json: Any) -> str:
    expected = f"\"{escape_moonbit_string(json_literal(expected_json))}\""
    source_literal = render_multiline_literal("source", expr)
    return (
        "///|\n"
        f"test \"generated/expr/{case_id:04d}\" {{\n"
        f"{source_literal}\n"
        "  let result = Interpreter::new().eval_source(source)\n"
        f"  let expected = {expected}\n"
        "  assert_run(result, expected)\n"
        "}\n\n"
    )


def render_program_test(case_id: int, lines: List[str], expected_json: Any) -> str:
    source = "\n".join(lines)
    expected = f"\"{escape_moonbit_string(json_literal(expected_json))}\""
    source_literal = render_multiline_literal("source", source)
    return (
        "///|\n"
        f"test \"generated/program/{case_id:04d}\" {{\n"
        f"{source_literal}\n"
        "  let result = Interpreter::new().exec_source(source)\n"
        f"  let expected = {expected}\n"
        "  assert_run(result, expected)\n"
        "}\n\n"
    )


def call_name(node: ast.AST) -> str:
    if isinstance(node, ast.Name):
        return node.id
    if isinstance(node, ast.Attribute):
        return node.attr
    return ""


def normalize_snippet(text: str) -> str:
    text = text.replace("\r\n", "\n").replace("\r", "\n")
    if "\x00" in text:
        return ""
    for ch in text:
        code = ord(ch)
        if 0xD800 <= code <= 0xDFFF:
            return ""
    text = textwrap.dedent(text)
    text = text.strip("\n")
    return text


def looks_like_code(text: str) -> bool:
    text = text.strip()
    if not text:
        return False
    # Avoid obvious non-code payloads.
    if len(text) > 800:
        return False
    if "http://" in text or "https://" in text:
        return False

    # Must contain at least one "code-ish" character.
    if not re.search(r"[\[\]{}()=:+\-*/%<>,.;]", text):
        return False

    # Heuristic: either multi-line, or has keywords/operators.
    if "\n" in text:
        return True

    if re.search(r"\b(def|class|if|else|elif|for|while|try|except|finally|with|return|yield|lambda|assert|import|from|raise|del|global|nonlocal)\b", text):
        return True

    # Expression-ish patterns.
    if re.search(r"\b(and|or|not|is|in)\b", text):
        return True

    return False


def classify_snippet(text: str) -> Tuple[str, str]:
    """Return (kind, normalized_text) where kind is 'expr' or 'program'."""
    snippet = normalize_snippet(text)
    if not looks_like_code(snippet):
        return "", ""

    # Multi-line snippets are overwhelmingly statements/blocks.
    if "\n" in snippet:
        try:
            ast.parse(snippet, mode="exec")
            return "program", snippet
        except (SyntaxError, ValueError, UnicodeError):
            return "program", snippet

    # Single-line: try expression first.
    try:
        ast.parse(snippet, mode="eval")
        return "expr", snippet
    except (SyntaxError, ValueError, UnicodeError):
        pass

    try:
        ast.parse(snippet, mode="exec")
        return "program", snippet
    except (SyntaxError, ValueError, UnicodeError):
        return "expr", snippet


def extract_code_literal(node: ast.AST) -> Optional[str]:
    if isinstance(node, ast.Constant) and isinstance(node.value, str):
        return node.value
    if isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):
        if node.func.attr == "dedent" and node.args:
            return extract_code_literal(node.args[0])
    if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):
        if node.func.id == "dedent" and node.args:
            return extract_code_literal(node.args[0])
    return None


def extract_string_arg(tokens: List[tokenize.TokenInfo]) -> Optional[str]:
    if not tokens:
        return None
    string_tokens = [tok for tok in tokens if tok.type == tokenize.STRING]
    if len(string_tokens) != len(tokens):
        return None
    parts = []
    for tok in string_tokens:
        try:
            literal = ast.literal_eval(tok.string)
        except Exception:
            return None
        if isinstance(literal, bytes):
            try:
                literal = literal.decode("utf-8", errors="ignore")
            except Exception:
                return None
        if not isinstance(literal, str):
            return None
        parts.append(literal)
    return "".join(parts)


def parse_call_args(tokens: List[tokenize.TokenInfo], start: int) -> Tuple[List[List[tokenize.TokenInfo]], int]:
    args: List[List[tokenize.TokenInfo]] = []
    current: List[tokenize.TokenInfo] = []
    depth = 0
    idx = start
    while idx < len(tokens):
        tok = tokens[idx]
        if tok.type == tokenize.OP and tok.string == "(":
            depth += 1
            if depth > 1:
                current.append(tok)
        elif tok.type == tokenize.OP and tok.string == ")":
            if depth == 1:
                if current:
                    args.append(current)
                return args, idx
            depth -= 1
            current.append(tok)
        elif tok.type == tokenize.OP and tok.string == "," and depth == 1:
            args.append(current)
            current = []
        else:
            if depth >= 1 and tok.type not in {tokenize.NL, tokenize.NEWLINE, tokenize.INDENT, tokenize.DEDENT}:
                current.append(tok)
        idx += 1
    return args, idx


def extract_cases_from_tokens(source: str) -> Tuple[List[str], List[List[str]]]:
    expr_cases: List[str] = []
    program_cases: List[List[str]] = []
    try:
        tokens = list(tokenize.generate_tokens(io.StringIO(source).readline))
    except tokenize.TokenError:
        return expr_cases, program_cases
    idx = 0
    while idx < len(tokens):
        tok = tokens[idx]
        if tok.type == tokenize.NAME:
            name = tok.string
            if name in {"eval", "exec", "compile", "check_syntax_error", "check_syntax_warning", "assertRaises", "assertRaisesRegex"}:
                # find next "(" token
                j = idx + 1
                while j < len(tokens) and not (tokens[j].type == tokenize.OP and tokens[j].string == "("):
                    j += 1
                if j >= len(tokens):
                    idx += 1
                    continue
                args, end_idx = parse_call_args(tokens, j)
                if name in {"eval", "exec"} and args:
                    code = extract_string_arg(args[0])
                    if code:
                        if name == "eval":
                            expr_cases.append(code)
                        else:
                            program_cases.append(code.splitlines())
                elif name == "compile" and len(args) >= 3:
                    code = extract_string_arg(args[0])
                    mode = extract_string_arg(args[2])
                    if code and mode == "eval":
                        expr_cases.append(code)
                    elif code and mode == "exec":
                        program_cases.append(code.splitlines())
                elif name in {"check_syntax_error", "check_syntax_warning"} and args:
                    code = extract_string_arg(args[0])
                    if code:
                        expr_cases.append(code)
                elif name in {"assertRaises", "assertRaisesRegex"} and len(args) >= 3:
                    error_name = args[0][0].string if args[0] else ""
                    target_name = args[1][0].string if args[1] else ""
                    code = extract_string_arg(args[2])
                    if code and error_name in {"SyntaxError", "IndentationError", "TabError"}:
                        if target_name in {"eval", "compile"}:
                            expr_cases.append(code)
                        elif target_name == "exec":
                            program_cases.append(code.splitlines())
                idx = end_idx
        idx += 1
    return expr_cases, program_cases


def extract_cases_from_file(path: Path) -> Tuple[List[str], List[List[str]]]:
    expr_cases: List[str] = []
    program_cases: List[List[str]] = []
    source = path.read_text(encoding="utf-8")
    try:
        tree = ast.parse(source, filename=str(path))
    except SyntaxError:
        return extract_cases_from_tokens(source)

    # 1) Structured extraction from common test helpers (high signal).
    for node in ast.walk(tree):
        if isinstance(node, ast.Call):
            name = call_name(node.func)
            if name in {"eval", "exec"} and node.args:
                code = extract_code_literal(node.args[0])
                if code:
                    if name == "eval":
                        expr_cases.append(code)
                    else:
                        program_cases.append(code.splitlines())
            elif name == "compile" and len(node.args) >= 3:
                code = extract_code_literal(node.args[0])
                mode = extract_code_literal(node.args[2])
                if code and mode == "eval":
                    expr_cases.append(code)
                elif code and mode == "exec":
                    program_cases.append(code.splitlines())
            elif name in {"check_syntax_error", "check_syntax_warning"} and node.args:
                code = extract_code_literal(node.args[0])
                if code:
                    expr_cases.append(code)
            elif name in {"assertRaises", "assertRaisesRegex"} and len(node.args) >= 3:
                error_type = call_name(node.args[0])
                target = call_name(node.args[1])
                code = extract_code_literal(node.args[2])
                if code and error_type in {"SyntaxError", "IndentationError", "TabError"}:
                    if target in {"eval", "compile"}:
                        expr_cases.append(code)
                    elif target == "exec":
                        program_cases.append(code.splitlines())

    # 2) Broad harvesting: scan string literals for code-like snippets.
    # Keep a per-file cap to avoid spending too long in huge modules.
    literal_added = 0
    LITERAL_LIMIT = 200
    for node in ast.walk(tree):
        if literal_added >= LITERAL_LIMIT:
            break
        if isinstance(node, ast.Constant) and isinstance(node.value, str):
            kind, snippet = classify_snippet(node.value)
            if not kind:
                continue
            if kind == "expr":
                expr_cases.append(snippet)
            else:
                program_cases.append(snippet.splitlines())
            literal_added += 1

    return expr_cases, program_cases


def collect_cpython_cases() -> Tuple[List[str], List[List[str]]]:
    if not CPYTHON_TEST_DIR.exists():
        raise FileNotFoundError(
            f"CPython tests not found at {CPYTHON_TEST_DIR}. Clone CPython first."
        )
    expr_cases: List[str] = []
    program_cases: List[List[str]] = []
    file_count = 0
    for path in sorted(CPYTHON_TEST_DIR.rglob("test_*.py")):
        file_exprs, file_programs = extract_cases_from_file(path)
        expr_cases.extend(file_exprs)
        program_cases.extend(file_programs)
        file_count += 1
        if file_count >= MAX_TEST_FILES:
            break
        if len(expr_cases) + len(program_cases) >= TOTAL_TARGET * 2:
            break
    return expr_cases, program_cases


def fetch_reference_pages() -> List[str]:
    REFERENCE_CACHE.mkdir(parents=True, exist_ok=True)
    pages: List[str] = []
    for url in REFERENCE_URLS:
        filename = url.rsplit("/", 1)[-1]
        path = REFERENCE_CACHE / filename
        if not path.exists():
            try:
                with urllib.request.urlopen(url, timeout=10) as response:
                    path.write_bytes(response.read())
            except Exception:
                continue
        try:
            pages.append(path.read_text(encoding="utf-8"))
        except Exception:
            continue
    return pages


def extract_code_blocks(text: str) -> List[str]:
    # python.org reference pages are HTML; try a lightweight HTML <pre> extractor first.
    lowered = text.lower()
    if "<html" in lowered and "<pre" in lowered:
        blocks: List[str] = []
        for raw in re.findall(r"<pre[^>]*>(.*?)</pre>", text, flags=re.IGNORECASE | re.DOTALL):
            cleaned = html.unescape(raw)
            cleaned = re.sub(r"<[^>]+>", "", cleaned)
            cleaned = cleaned.replace("\r\n", "\n").replace("\r", "\n")
            cleaned = cleaned.strip("\n")
            if cleaned:
                blocks.append(cleaned)
        return blocks

    blocks: List[str] = []
    lines = text.splitlines()
    idx = 0
    while idx < len(lines):
        line = lines[idx]
        if line.strip().startswith(".. code-block::") and "python" in line:
            idx += 1
            while idx < len(lines) and lines[idx].strip() == "":
                idx += 1
            if idx >= len(lines):
                break
            indent = len(lines[idx]) - len(lines[idx].lstrip())
            block_lines = []
            while idx < len(lines):
                current = lines[idx]
                if current.strip() == "":
                    block_lines.append("")
                    idx += 1
                    continue
                current_indent = len(current) - len(current.lstrip())
                if current_indent < indent:
                    break
                block_lines.append(current[indent:])
                idx += 1
            blocks.append("\n".join(block_lines).rstrip())
            continue
        if line.rstrip().endswith("::"):
            idx += 1
            while idx < len(lines) and lines[idx].strip() == "":
                idx += 1
            if idx >= len(lines):
                break
            indent = len(lines[idx]) - len(lines[idx].lstrip())
            block_lines = []
            while idx < len(lines):
                current = lines[idx]
                if current.strip() == "":
                    block_lines.append("")
                    idx += 1
                    continue
                current_indent = len(current) - len(current.lstrip())
                if current_indent < indent:
                    break
                block_lines.append(current[indent:])
                idx += 1
            blocks.append("\n".join(block_lines).rstrip())
            continue
        idx += 1
    return [block for block in blocks if block]


def normalize_repl_block(block: str) -> str:
    lines = block.splitlines()
    has_prompt = any(line.lstrip().startswith(">>>") for line in lines)
    if not has_prompt:
        return block
    program_lines = []
    for line in lines:
        stripped = line.lstrip()
        if stripped.startswith(">>> "):
            program_lines.append(stripped[4:])
        elif stripped.startswith("... "):
            program_lines.append(stripped[4:])
    return "\n".join(program_lines).strip()


def collect_reference_cases() -> Tuple[List[str], List[List[str]]]:
    expr_cases: List[str] = []
    program_cases: List[List[str]] = []
    for page in fetch_reference_pages():
        for block in extract_code_blocks(page):
            snippet = normalize_repl_block(block)
            if not snippet:
                continue
            if snippet.startswith("#"):
                continue
            try:
                ast.parse(snippet, mode="eval")
                expr_cases.append(snippet)
                continue
            except SyntaxError:
                pass
            try:
                ast.parse(snippet, mode="exec")
                program_cases.append(snippet.splitlines())
            except SyntaxError:
                continue
    return expr_cases, program_cases


def dedupe_expr(cases: List[str]) -> List[str]:
    seen = set()
    result = []
    for case in cases:
        if case in seen:
            continue
        seen.add(case)
        result.append(case)
    return result


def dedupe_programs(cases: List[List[str]]) -> List[List[str]]:
    seen = set()
    result = []
    for case in cases:
        key = "\n".join(case)
        if key in seen:
            continue
        seen.add(key)
        result.append(case)
    return result


def main() -> None:
    expr_cases, program_cases = collect_cpython_cases()
    ref_expr_cases, ref_program_cases = collect_reference_cases()

    expr_pool = dedupe_expr(ref_expr_cases + expr_cases)
    program_pool = dedupe_programs(ref_program_cases + program_cases)

    tests: List[str] = [LICENSE_HEADER]

    # Prefer tests that have a meaningful value/output.
    # Many programs are valid but have no visible side effects (so they return None),
    # so we cap those to keep the suite interesting.

    expr_ok_good: List[Tuple[str, Any]] = []
    expr_ok_none: List[Tuple[str, Any]] = []
    expr_err: List[Tuple[str, Any]] = []

    for expr in expr_pool:
        try:
            value, stdout, stderr = eval_expression(expr)
            expected_json = ["ok", value_to_json(value), stdout, stderr]
        except EvalTimeout:
            continue
        except SyntaxError as err:
            expected_json = ["err", format_error(err)]
        except Exception as err:
            expected_json = ["err", format_error(err)]

        if expected_json[0] == "err":
            expr_err.append((expr, expected_json))
            continue

        payload, out, err_out = expected_json[1], expected_json[2], expected_json[3]
        if payload == "None" and out == "" and err_out == "":
            expr_ok_none.append((expr, expected_json))
        else:
            expr_ok_good.append((expr, expected_json))

        if len(expr_ok_good) >= EXPR_TARGET and len(expr_ok_none) >= EXPR_TARGET // 4:
            break

    expr_ok_none_cap = EXPR_TARGET // 4
    expr_err_cap = EXPR_TARGET // 3

    case_id = 1
    for expr, expected_json in expr_ok_good:
        if case_id > EXPR_TARGET:
            break
        try:
            tests.append(render_expr_test(case_id, expr, expected_json))
            case_id += 1
        except Exception:
            continue

    for expr, expected_json in expr_ok_none:
        if case_id > EXPR_TARGET:
            break
        if expr_ok_none_cap <= 0:
            break
        try:
            tests.append(render_expr_test(case_id, expr, expected_json))
            case_id += 1
            expr_ok_none_cap -= 1
        except Exception:
            continue

    for expr, expected_json in expr_err:
        if case_id > EXPR_TARGET:
            break
        if expr_err_cap <= 0:
            break
        try:
            tests.append(render_expr_test(case_id, expr, expected_json))
            case_id += 1
            expr_err_cap -= 1
        except Exception:
            continue

    # If we still haven't reached EXPR_TARGET, fill with remaining ok-none then errors.
    if case_id <= EXPR_TARGET:
        for expr, expected_json in expr_ok_none:
            if case_id > EXPR_TARGET:
                break
            try:
                tests.append(render_expr_test(case_id, expr, expected_json))
                case_id += 1
            except Exception:
                continue

    if case_id <= EXPR_TARGET:
        for expr, expected_json in expr_err:
            if case_id > EXPR_TARGET:
                break
            try:
                tests.append(render_expr_test(case_id, expr, expected_json))
                case_id += 1
            except Exception:
                continue

    prog_ok_output: List[Tuple[List[str], Any]] = []
    prog_ok_quiet: List[Tuple[List[str], Any]] = []
    prog_err: List[Tuple[List[str], Any]] = []

    for program in program_pool:
        try:
            value, stdout, stderr = eval_program(program)
            expected_json = ["ok", value_to_json(value), stdout, stderr]
        except EvalTimeout:
            continue
        except SyntaxError as err:
            expected_json = ["err", format_error(err)]
        except Exception as err:
            expected_json = ["err", format_error(err)]

        if expected_json[0] == "err":
            prog_err.append((program, expected_json))
            continue

        out, err_out = expected_json[2], expected_json[3]
        if out == "" and err_out == "":
            prog_ok_quiet.append((program, expected_json))
        else:
            prog_ok_output.append((program, expected_json))

        if len(prog_ok_output) >= PROGRAM_TARGET and len(prog_ok_quiet) >= PROGRAM_TARGET // 4:
            break

    prog_ok_quiet_cap = PROGRAM_TARGET // 4
    prog_err_cap = PROGRAM_TARGET

    program_id = 1
    for program, expected_json in prog_ok_output:
        if program_id > PROGRAM_TARGET:
            break
        try:
            tests.append(render_program_test(program_id, program, expected_json))
            program_id += 1
        except Exception:
            continue

    for program, expected_json in prog_ok_quiet:
        if program_id > PROGRAM_TARGET:
            break
        if prog_ok_quiet_cap <= 0:
            break
        try:
            tests.append(render_program_test(program_id, program, expected_json))
            program_id += 1
            prog_ok_quiet_cap -= 1
        except Exception:
            continue

    for program, expected_json in prog_err:
        if program_id > PROGRAM_TARGET:
            break
        if prog_err_cap <= 0:
            break
        try:
            tests.append(render_program_test(program_id, program, expected_json))
            program_id += 1
            prog_err_cap -= 1
        except Exception:
            continue

    if program_id <= PROGRAM_TARGET:
        for program, expected_json in prog_err:
            if program_id > PROGRAM_TARGET:
                break
            try:
                tests.append(render_program_test(program_id, program, expected_json))
                program_id += 1
            except Exception:
                continue

    OUTPUT_FILE.write_text("".join(tests), encoding="utf-8")


if __name__ == "__main__":
    main()

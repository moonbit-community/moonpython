#!/usr/bin/env python3
"""
Generate spec-driven tests from official CPython resources.

Regenerate with:
  python3 scripts/generate_spec_tests.py
"""

from __future__ import annotations

import ast
import contextlib
import importlib
import io
import json
import math
import re
import tokenize
import urllib.request
import warnings
from pathlib import Path
from typing import Any, List, Optional, Tuple

OUTPUT_FILE = Path(__file__).parent.parent / "spec_generated_test.mbt"
CPYTHON_ROOT = Path(__file__).parent.parent / "cpython-tests"
CPYTHON_TEST_DIR = CPYTHON_ROOT / "Lib" / "test"
REFERENCE_VERSION = "3.13"
REFERENCE_CACHE = Path(__file__).parent / "reference_cache" / REFERENCE_VERSION

TOTAL_TARGET = 2000
EXPR_TARGET = 1000
PROGRAM_TARGET = 1000
MAX_TEST_FILES = 200
REFERENCE_URLS = [
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/expressions.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/simple_stmts.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/compound_stmts.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/datamodel.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/lexical_analysis.html",
    f"https://docs.python.org/{REFERENCE_VERSION}/reference/executionmodel.html",
]

LICENSE_HEADER = """// ============================================================================
// AUTO-GENERATED FILE - DO NOT MODIFY MANUALLY
// Generated by: scripts/generate_spec_tests.py
// Regenerate with: python3 scripts/generate_spec_tests.py
// ============================================================================

///|
/// MPython spec-driven tests generated from CPython evaluation

fn assert_run(result : Result[RunResult, RuntimeError], expected : String) -> Unit raise {
  let json = @json.parse(expected) catch { _ => fail("invalid json") }
  match json {
    Array(items) => {
      if items.length() < 2 {
        fail("invalid expectation")
      }
      let tag = items[0]
      match tag {
        String(tag) =>
          if tag == "ok" {
            if items.length() != 4 {
              fail("invalid expectation")
            }
            let payload = items[1]
            let stdout = items[2]
            let stderr = items[3]
            match result {
              Ok(run) => {
                @json.inspect(run.value, content=payload)
                match stdout {
                  String(text) => inspect(run.stdout, content=text)
                  _ => fail("invalid expectation")
                }
                match stderr {
                  String(text) => inspect(run.stderr, content=text)
                  _ => fail("invalid expectation")
                }
              }
              Err(err) => fail(format_runtime_error(err))
            }
          } else if tag == "err" {
            if items.length() != 2 {
              fail("invalid expectation")
            }
            let payload = items[1]
            match result {
              Ok(_) => fail("expected error")
              Err(err) =>
                match payload {
                  String(message) =>
                    inspect(format_runtime_error(err), content=message)
                  _ => fail("invalid error payload")
                }
            }
          } else {
            fail("invalid expectation")
          }
        _ => fail("invalid expectation")
      }
    }
    _ => fail("invalid expectation")
  }
}

"""


def escape_moonbit_string(value: str) -> str:
    value = value.replace("\\", "\\\\")
    value = value.replace('"', "\\\"")
    value = value.replace("\r", "")
    value = value.replace("\n", "\\n")
    value = value.replace("\t", "\\t")
    return value


def render_multiline_literal(name: str, text: str, indent: str = "  ") -> str:
    lines = text.splitlines()
    if text.endswith("\n"):
        lines.append("")
    result = [f"{indent}let {name} ="]
    if not lines:
        result.append(f"{indent}  #|")
        return "\n".join(result)
    for line in lines:
        result.append(f"{indent}  #|{line}")
    return "\n".join(result)


def safe_import(name: str, globals: Any = None, locals: Any = None, fromlist: Any = (), level: int = 0) -> Any:
    if name in {"math", "functools", "itertools"}:
        return importlib.import_module(name)
    raise ImportError(f"module {name} is not allowed")


SAFE_BUILTINS = {
    "__import__": safe_import,
    "len": len,
    "range": range,
    "str": str,
    "int": int,
    "float": float,
    "list": list,
    "dict": dict,
    "set": set,
    "tuple": tuple,
    "enumerate": enumerate,
    "zip": zip,
    "map": map,
    "filter": filter,
    "any": any,
    "all": all,
    "sum": sum,
    "print": print,
}


def eval_expression(expr: str) -> Tuple[Any, str, str]:
    env = {"__builtins__": SAFE_BUILTINS}
    stdout = io.StringIO()
    stderr = io.StringIO()
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", SyntaxWarning)
        with contextlib.redirect_stdout(stdout), contextlib.redirect_stderr(stderr):
            value = eval(expr, env, env)
    return value, stdout.getvalue(), stderr.getvalue()


def eval_program(lines: List[str]) -> Tuple[Any, str, str]:
    env = {"__builtins__": SAFE_BUILTINS}
    if not lines:
        return None, "", ""
    stdout = io.StringIO()
    stderr = io.StringIO()
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", SyntaxWarning)
        with contextlib.redirect_stdout(stdout), contextlib.redirect_stderr(stderr):
            exec("\n".join(lines), env, env)
    return None, stdout.getvalue(), stderr.getvalue()


def format_error(err: Exception) -> str:
    if isinstance(err, SyntaxError):
        line = err.lineno or 1
        column = err.offset or 1
        message = err.msg or "invalid syntax"
        return f"line {line}:{column} {message}"
    return f"{err.__class__.__name__}: {err}"



def is_supported_expr(expr: str) -> bool:
    try:
        tree = ast.parse(expr, mode="eval")
    except (SyntaxError, ValueError):
        return False
    allowed = {
        ast.Expression,
        ast.Name,
        ast.Constant,
        ast.Load,
        ast.BinOp,
        ast.UnaryOp,
        ast.BoolOp,
        ast.Compare,
        ast.Call,
        ast.List,
        ast.Tuple,
        ast.Dict,
        ast.Subscript,
        ast.Slice,
        ast.Lambda,
        ast.IfExp,
        ast.Add,
        ast.Sub,
        ast.Mult,
        ast.Div,
        ast.FloorDiv,
        ast.Mod,
        ast.Pow,
        ast.UAdd,
        ast.USub,
        ast.Not,
        ast.Invert,
        ast.And,
        ast.Or,
        ast.Eq,
        ast.NotEq,
        ast.Lt,
        ast.LtE,
        ast.Gt,
        ast.GtE,
        ast.Is,
        ast.IsNot,
        ast.In,
        ast.NotIn,
    }
    for node in ast.walk(tree):
        if isinstance(node, ast.Call) and node.keywords:
            return False
        if type(node) not in allowed:
            return False
    return True


def is_supported_program(lines: List[str]) -> bool:
    try:
        tree = ast.parse("\n".join(lines), mode="exec")
    except (SyntaxError, ValueError):
        return False
    allowed = {
        ast.Module,
        ast.Expr,
        ast.Assign,
        ast.Name,
        ast.Constant,
        ast.Load,
        ast.Store,
        ast.BinOp,
        ast.UnaryOp,
        ast.BoolOp,
        ast.Compare,
        ast.Call,
        ast.List,
        ast.Tuple,
        ast.Dict,
        ast.Subscript,
        ast.Slice,
        ast.arguments,
        ast.arg,
        ast.FunctionDef,
        ast.Return,
        ast.Lambda,
        ast.IfExp,
        ast.Add,
        ast.Sub,
        ast.Mult,
        ast.Div,
        ast.FloorDiv,
        ast.Mod,
        ast.Pow,
        ast.UAdd,
        ast.USub,
        ast.Not,
        ast.Invert,
        ast.And,
        ast.Or,
        ast.Eq,
        ast.NotEq,
        ast.Lt,
        ast.LtE,
        ast.Gt,
        ast.GtE,
        ast.Is,
        ast.IsNot,
        ast.In,
        ast.NotIn,
    }
    for node in ast.walk(tree):
        if isinstance(node, ast.Assign):
            if len(node.targets) != 1 or not isinstance(node.targets[0], ast.Name):
                return False
        if isinstance(node, ast.FunctionDef):
            if node.end_lineno is not None and node.end_lineno == node.lineno:
                return False
        if isinstance(node, ast.Call) and node.keywords:
            return False
        if type(node) not in allowed:
            return False
    return True


def value_to_json(value: Any) -> Any:
    if value is None:
        return "None"
    if isinstance(value, bool):
        return ["Bool", value]
    if isinstance(value, int):
        return ["Int", str(value)]
    if isinstance(value, float):
        if math.isnan(value) or math.isinf(value):
            raise ValueError("unsupported float")
        return ["Float", value]
    if isinstance(value, str):
        return ["Str", value]
    if isinstance(value, list):
        return ["List", [value_to_json(item) for item in value]]
    if isinstance(value, tuple):
        return ["Tuple", [value_to_json(item) for item in value]]
    if isinstance(value, set):
        return ["Set", [value_to_json(item) for item in value]]
    if isinstance(value, dict):
        return [
            "Dict",
            [[value_to_json(key), value_to_json(val)] for key, val in value.items()],
        ]
    raise ValueError("unsupported value")


def json_literal(value: Any) -> str:
    return json.dumps(value, ensure_ascii=False)


def render_expr_test(case_id: int, expr: str, expected_json: Any) -> str:
    expected = f"\"{escape_moonbit_string(json_literal(expected_json))}\""
    source_literal = render_multiline_literal("source", expr)
    return (
        "///|\n"
        f"test \"generated/expr/{case_id:04d}\" {{\n"
        f"{source_literal}\n"
        "  let result = Interpreter::new().exec_source(source)\n"
        f"  let expected = {expected}\n"
        "  assert_run(result, expected)\n"
        "}\n\n"
    )


def render_program_test(case_id: int, lines: List[str], expected_json: Any) -> str:
    source = "\n".join(lines)
    expected = f"\"{escape_moonbit_string(json_literal(expected_json))}\""
    source_literal = render_multiline_literal("source", source)
    return (
        "///|\n"
        f"test \"generated/program/{case_id:04d}\" {{\n"
        f"{source_literal}\n"
        "  let result = Interpreter::new().exec_source(source)\n"
        f"  let expected = {expected}\n"
        "  assert_run(result, expected)\n"
        "}\n\n"
    )


def call_name(node: ast.AST) -> str:
    if isinstance(node, ast.Name):
        return node.id
    if isinstance(node, ast.Attribute):
        return node.attr
    return ""


def extract_code_literal(node: ast.AST) -> Optional[str]:
    if isinstance(node, ast.Constant) and isinstance(node.value, str):
        return node.value
    if isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):
        if node.func.attr == "dedent" and node.args:
            return extract_code_literal(node.args[0])
    if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):
        if node.func.id == "dedent" and node.args:
            return extract_code_literal(node.args[0])
    return None


def extract_string_arg(tokens: List[tokenize.TokenInfo]) -> Optional[str]:
    if not tokens:
        return None
    string_tokens = [tok for tok in tokens if tok.type == tokenize.STRING]
    if len(string_tokens) != len(tokens):
        return None
    parts = []
    for tok in string_tokens:
        try:
            literal = ast.literal_eval(tok.string)
        except Exception:
            return None
        if isinstance(literal, bytes):
            try:
                literal = literal.decode("utf-8", errors="ignore")
            except Exception:
                return None
        if not isinstance(literal, str):
            return None
        parts.append(literal)
    return "".join(parts)


def parse_call_args(tokens: List[tokenize.TokenInfo], start: int) -> Tuple[List[List[tokenize.TokenInfo]], int]:
    args: List[List[tokenize.TokenInfo]] = []
    current: List[tokenize.TokenInfo] = []
    depth = 0
    idx = start
    while idx < len(tokens):
        tok = tokens[idx]
        if tok.type == tokenize.OP and tok.string == "(":
            depth += 1
            if depth > 1:
                current.append(tok)
        elif tok.type == tokenize.OP and tok.string == ")":
            if depth == 1:
                if current:
                    args.append(current)
                return args, idx
            depth -= 1
            current.append(tok)
        elif tok.type == tokenize.OP and tok.string == "," and depth == 1:
            args.append(current)
            current = []
        else:
            if depth >= 1 and tok.type not in {tokenize.NL, tokenize.NEWLINE, tokenize.INDENT, tokenize.DEDENT}:
                current.append(tok)
        idx += 1
    return args, idx


def extract_cases_from_tokens(source: str) -> Tuple[List[str], List[List[str]]]:
    expr_cases: List[str] = []
    program_cases: List[List[str]] = []
    try:
        tokens = list(tokenize.generate_tokens(io.StringIO(source).readline))
    except tokenize.TokenError:
        return expr_cases, program_cases
    idx = 0
    while idx < len(tokens):
        tok = tokens[idx]
        if tok.type == tokenize.NAME:
            name = tok.string
            if name in {"eval", "exec", "compile", "check_syntax_error", "check_syntax_warning", "assertRaises", "assertRaisesRegex"}:
                # find next "(" token
                j = idx + 1
                while j < len(tokens) and not (tokens[j].type == tokenize.OP and tokens[j].string == "("):
                    j += 1
                if j >= len(tokens):
                    idx += 1
                    continue
                args, end_idx = parse_call_args(tokens, j)
                if name in {"eval", "exec"} and args:
                    code = extract_string_arg(args[0])
                    if code:
                        if name == "eval":
                            expr_cases.append(code)
                        else:
                            program_cases.append(code.splitlines())
                elif name == "compile" and len(args) >= 3:
                    code = extract_string_arg(args[0])
                    mode = extract_string_arg(args[2])
                    if code and mode == "eval":
                        expr_cases.append(code)
                    elif code and mode == "exec":
                        program_cases.append(code.splitlines())
                elif name in {"check_syntax_error", "check_syntax_warning"} and args:
                    code = extract_string_arg(args[0])
                    if code:
                        expr_cases.append(code)
                elif name in {"assertRaises", "assertRaisesRegex"} and len(args) >= 3:
                    error_name = args[0][0].string if args[0] else ""
                    target_name = args[1][0].string if args[1] else ""
                    code = extract_string_arg(args[2])
                    if code and error_name in {"SyntaxError", "IndentationError", "TabError"}:
                        if target_name in {"eval", "compile"}:
                            expr_cases.append(code)
                        elif target_name == "exec":
                            program_cases.append(code.splitlines())
                idx = end_idx
        idx += 1
    return expr_cases, program_cases


def extract_cases_from_file(path: Path) -> Tuple[List[str], List[List[str]]]:
    expr_cases: List[str] = []
    program_cases: List[List[str]] = []
    source = path.read_text(encoding="utf-8")
    try:
        tree = ast.parse(source, filename=str(path))
    except SyntaxError:
        return extract_cases_from_tokens(source)

    for node in ast.walk(tree):
        if isinstance(node, ast.Call):
            name = call_name(node.func)
            if name in {"eval", "exec"} and node.args:
                code = extract_code_literal(node.args[0])
                if code:
                    if name == "eval":
                        expr_cases.append(code)
                    else:
                        program_cases.append(code.splitlines())
            elif name == "compile" and len(node.args) >= 3:
                code = extract_code_literal(node.args[0])
                mode = extract_code_literal(node.args[2])
                if code and mode == "eval":
                    expr_cases.append(code)
                elif code and mode == "exec":
                    program_cases.append(code.splitlines())
            elif name in {"check_syntax_error", "check_syntax_warning"} and node.args:
                code = extract_code_literal(node.args[0])
                if code:
                    expr_cases.append(code)
            elif name in {"assertRaises", "assertRaisesRegex"} and len(node.args) >= 3:
                error_type = call_name(node.args[0])
                target = call_name(node.args[1])
                code = extract_code_literal(node.args[2])
                if code and error_type in {"SyntaxError", "IndentationError", "TabError"}:
                    if target in {"eval", "compile"}:
                        expr_cases.append(code)
                    elif target == "exec":
                        program_cases.append(code.splitlines())
    return expr_cases, program_cases


def collect_cpython_cases() -> Tuple[List[str], List[List[str]]]:
    if not CPYTHON_TEST_DIR.exists():
        raise FileNotFoundError(
            f"CPython tests not found at {CPYTHON_TEST_DIR}. Clone CPython first."
        )
    expr_cases: List[str] = []
    program_cases: List[List[str]] = []
    file_count = 0
    for path in sorted(CPYTHON_TEST_DIR.rglob("test_*.py")):
        file_exprs, file_programs = extract_cases_from_file(path)
        expr_cases.extend(file_exprs)
        program_cases.extend(file_programs)
        file_count += 1
        if file_count >= MAX_TEST_FILES:
            break
        if len(expr_cases) + len(program_cases) >= TOTAL_TARGET * 3:
            break
    return expr_cases, program_cases


def fetch_reference_pages() -> List[str]:
    REFERENCE_CACHE.mkdir(parents=True, exist_ok=True)
    pages: List[str] = []
    for url in REFERENCE_URLS:
        filename = url.rsplit("/", 1)[-1]
        path = REFERENCE_CACHE / filename
        if not path.exists():
            try:
                with urllib.request.urlopen(url, timeout=10) as response:
                    path.write_bytes(response.read())
            except Exception:
                continue
        try:
            pages.append(path.read_text(encoding="utf-8"))
        except Exception:
            continue
    return pages


def extract_code_blocks(text: str) -> List[str]:
    blocks: List[str] = []
    lines = text.splitlines()
    idx = 0
    while idx < len(lines):
        line = lines[idx]
        if line.strip().startswith(".. code-block::") and "python" in line:
            idx += 1
            while idx < len(lines) and lines[idx].strip() == "":
                idx += 1
            if idx >= len(lines):
                break
            indent = len(lines[idx]) - len(lines[idx].lstrip())
            block_lines = []
            while idx < len(lines):
                current = lines[idx]
                if current.strip() == "":
                    block_lines.append("")
                    idx += 1
                    continue
                current_indent = len(current) - len(current.lstrip())
                if current_indent < indent:
                    break
                block_lines.append(current[indent:])
                idx += 1
            blocks.append("\n".join(block_lines).rstrip())
            continue
        if line.rstrip().endswith("::"):
            idx += 1
            while idx < len(lines) and lines[idx].strip() == "":
                idx += 1
            if idx >= len(lines):
                break
            indent = len(lines[idx]) - len(lines[idx].lstrip())
            block_lines = []
            while idx < len(lines):
                current = lines[idx]
                if current.strip() == "":
                    block_lines.append("")
                    idx += 1
                    continue
                current_indent = len(current) - len(current.lstrip())
                if current_indent < indent:
                    break
                block_lines.append(current[indent:])
                idx += 1
            blocks.append("\n".join(block_lines).rstrip())
            continue
        idx += 1
    return [block for block in blocks if block]


def normalize_repl_block(block: str) -> str:
    lines = block.splitlines()
    has_prompt = any(line.lstrip().startswith(">>>") for line in lines)
    if not has_prompt:
        return block
    program_lines = []
    for line in lines:
        stripped = line.lstrip()
        if stripped.startswith(">>> "):
            program_lines.append(stripped[4:])
        elif stripped.startswith("... "):
            program_lines.append(stripped[4:])
    return "\n".join(program_lines).strip()


def collect_reference_cases() -> Tuple[List[str], List[List[str]]]:
    expr_cases: List[str] = []
    program_cases: List[List[str]] = []
    for page in fetch_reference_pages():
        for block in extract_code_blocks(page):
            snippet = normalize_repl_block(block)
            if not snippet:
                continue
            if snippet.startswith("#"):
                continue
            try:
                ast.parse(snippet, mode="eval")
                expr_cases.append(snippet)
                continue
            except SyntaxError:
                pass
            try:
                ast.parse(snippet, mode="exec")
                program_cases.append(snippet.splitlines())
            except SyntaxError:
                continue
    return expr_cases, program_cases


def dedupe_expr(cases: List[str]) -> List[str]:
    seen = set()
    result = []
    for case in cases:
        if case in seen:
            continue
        seen.add(case)
        result.append(case)
    return result


def dedupe_programs(cases: List[List[str]]) -> List[List[str]]:
    seen = set()
    result = []
    for case in cases:
        key = "\n".join(case)
        if key in seen:
            continue
        seen.add(key)
        result.append(case)
    return result


def main() -> None:
    expr_cases, program_cases = collect_cpython_cases()
    ref_expr_cases, ref_program_cases = collect_reference_cases()

    expr_cases = dedupe_expr(ref_expr_cases + expr_cases)
    program_cases = dedupe_programs(ref_program_cases + program_cases)

    expr_cases = expr_cases[:EXPR_TARGET]
    program_cases = program_cases[:PROGRAM_TARGET]

    tests: List[str] = [LICENSE_HEADER]

    case_id = 1
    for expr in expr_cases:
        if not is_supported_expr(expr):
            continue
        try:
            value, stdout, stderr = eval_expression(expr)
            expected_json = ["ok", value_to_json(value), stdout, stderr]
        except SyntaxError:
            continue
        except Exception as err:
            expected_json = ["err", format_error(err)]
        try:
            tests.append(render_expr_test(case_id, expr, expected_json))
        except Exception:
            continue
        case_id += 1

    program_id = 1
    for program in program_cases:
        if not is_supported_program(program):
            continue
        try:
            value, stdout, stderr = eval_program(program)
            expected_json = ["ok", value_to_json(value), stdout, stderr]
        except SyntaxError:
            continue
        except Exception as err:
            expected_json = ["err", format_error(err)]
        try:
            tests.append(render_program_test(program_id, program, expected_json))
        except Exception:
            continue
        program_id += 1

    OUTPUT_FILE.write_text("".join(tests), encoding="utf-8")


if __name__ == "__main__":
    main()
